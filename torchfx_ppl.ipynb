{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "torchfx_ppl.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jpchen/playground/blob/master/torchfx_ppl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NObQCRohyneF"
      },
      "source": [
        "# Useful program transformations for PPLs \n",
        "*@neerajprad, @jpchen, @xiaoyan0*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3f_S65QE18Qh"
      },
      "source": [
        "This notebook contains example probabilistic inference workflows as well as a complete example written in both JAX as well as PyTorch for comparison purposes. The code snippets are from the Leapfrog integrator that is used within a very popular MCMC inference algorithm called the No-U-Turn Sampler (NUTS) [[1](#scrollTo=3URBZvuod6-3&line=1&uniqifier=1)]. \n",
        "\n",
        "This code does not contain dependency on a particular PPL so that it is easier to compare differences between the two frameworks, particularly as it relates to features that will be important for any PyTorch-based PPL. Examples in Section 1 are small snippets in PyTorch for illustration purposes and code in section 2 further exemplifies these points by comparing a complete implementation of a Leapfrog integrator across JAX and PyTorch.\n",
        "\n",
        "1. [Control Flow Examples](#scrollTo=0Pc-BvLTtcAM&uniqifier=1)\n",
        "   - [Composition with grad](#scrollTo=mfmeUyh8voEM&uniqifier=1)\n",
        "   - [Stochastic Control Flow](#scrollTo=TaVj14XQvDm-&uniqifier=1)\n",
        "   - [Composition with Looping Primitives](#scrollTo=PsV7hBZzwpdl&uniqifier=1)\n",
        "   - [Composition with JIT](#scrollTo=pjouiqlzutPX&uniqifier=1)\n",
        "2. [JAX NUTS example: Leapfrog integrator](#scrollTo=rztOk3U_YUF8&uniqifier=1)\n",
        "3. [PyTorch NUTS example: Leapfrog integrator](#scrollTo=hV_wTvKG9Xli&uniqifier=1)\n",
        "4. [Helpful References](#scrollTo=3URBZvuod6-3&uniqifier=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Pc-BvLTtcAM"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## 1. Control Flow Examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pReoWxG0yO6",
        "outputId": "36c1d3a6-1697-4ec9-83ec-7bd854cdca44"
      },
      "source": [
        "%reset -sf\n",
        "\n",
        "#install nightly version for access to torch.vmap\n",
        "!pip install --upgrade --pre torch==1.9.0.dev20210219 torchvision torchaudio -f https://download.pytorch.org/whl/nightly/cu102/torch_nightly.html\n",
        "\n",
        "import torch\n",
        "import torch.distributions as dist\n",
        "from torch.autograd import grad\n",
        "\n",
        "print('pytorch version: ', torch.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/nightly/cu102/torch_nightly.html\n",
            "Requirement already up-to-date: torch==1.9.0.dev20210219 in /usr/local/lib/python3.6/dist-packages (1.9.0.dev20210219)\n",
            "Requirement already up-to-date: torchvision in /usr/local/lib/python3.6/dist-packages (0.9.0.dev20210219)\n",
            "Requirement already up-to-date: torchaudio in /usr/local/lib/python3.6/dist-packages (0.8.0.dev20210219)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch==1.9.0.dev20210219) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.9.0.dev20210219) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from torch==1.9.0.dev20210219) (0.8)\n",
            "Requirement already satisfied, skipping upgrade: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (7.0.0)\n",
            "pytorch version:  1.9.0.dev20210219\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfmeUyh8voEM"
      },
      "source": [
        "### a) Composition with grad\n",
        "At the core of the algorithm is a symplectic integrator that requires taking iterative gradients [[1](#scrollTo=PsV7hBZzwpdl&line=1&uniqifier=1)]. `vmap` or `jit` at the outermost loop would need to be able to handle this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bQeor4MtkAn",
        "outputId": "bbd32d07-cd64-404b-b0d1-c22042dc4410"
      },
      "source": [
        "# This is one of the operations in the leapfrog integrator in [1]. The full integrator is \n",
        "# in the complete example in Sec. 2.\n",
        "\n",
        "def grad_fn(node, params):\n",
        "    # compute grad (of a stochastic value)\n",
        "    grad = torch.autograd.grad(node, params)\n",
        "    # update node\n",
        "    new_node = node + grad[0]\n",
        "    return new_node\n",
        "\n",
        "params = [torch.tensor(0., requires_grad=True), torch.tensor(1., requires_grad=True)]\n",
        "node = dist.Normal(*params).log_prob(torch.tensor(0.3))\n",
        "grad_fn(node, params)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-0.6639, grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaVj14XQvDm-"
      },
      "source": [
        "### b) Stochastic Control Flow\n",
        "In most workflows we need a way to determine control flow pseudorandomly. JAX handles this through a local functional [RNG](https://jax.readthedocs.io/en/latest/jax.random.html). This is to say that both `jit` and `vmap` need to be able to handle the stochastic `accept > 0` condition. This is easier in JAX because there is no global RNG, and the JIT traces through the RNG splitting to be able to do this. Supporting this in PyTorch will be hard without a corresponding functional random number generator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8Sa8cwIt6Ji"
      },
      "source": [
        "# (this is the Metropolis Hastings correction step in [1])\n",
        "def accept_or_reject(v):\n",
        "  # sample from prng. conditioned on the inputs in practice\n",
        "  accept_prob = dist.Normal(0., 1.).log_prob(v)\n",
        "  # accept `accept_prob` % of the time\n",
        "  accept = dist.Bernoulli(logits=accept_prob).sample()\n",
        "  if accept > 0:\n",
        "    return torch.tensor(1.)\n",
        "  return torch.tensor(0.)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsV7hBZzwpdl"
      },
      "source": [
        "### c) Compositon with Looping Primitives\n",
        "\n",
        "In Bean Machine we have a set of nodes we are updating at each iteration. Since the updates are conditional on the dependency graph, we do this in a for-loop."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilZfga0nwprV"
      },
      "source": [
        "# looping primitives for node updates with conditionals\n",
        "# outermost loop, composing all of the functions above\n",
        "\n",
        "def update_nodes(nodes):\n",
        "  # loop through, update some nodes given a condition\n",
        "  for n in nodes:\n",
        "    if accept_or_reject(n.val).item() > 0:\n",
        "      # update node value (technically also the nodes in the markov blanket)\n",
        "      # todo: do this in a non-mutating way\n",
        "      proposed_value = dist.Normal(0., 1.).sample()\n",
        "      n.val = proposed_value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjouiqlzutPX"
      },
      "source": [
        "### d) Composition with JIT\n",
        "A functional grad that composes with JIT and actually inlines the backward operations (for optimization like JAX will be really useful. The issue here is that we need to set `requires_grad` to `True` in `_potential_grad` and the tracer complains about that. In the example below, a functional version of `grad` will be really useful so that the JIT does not complain about inserting a constant with `requires_grad` set to True."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "2EcPQpntuGaK",
        "outputId": "d0311b25-8c6e-4ed8-c4a9-b286e0c5dc25"
      },
      "source": [
        "def fn(x):\n",
        "  # It will be nice to have a functional grad variant that does not require us\n",
        "  # to set `requires_grad` to True.\n",
        "  x.requires_grad_(True)\n",
        "  y = x**3\n",
        "  grad = torch.autograd.grad(y, x)\n",
        "  x.requires_grad_(False)\n",
        "  return x + grad\n",
        "\n",
        "\n",
        "torch.jit.trace(fn, torch.tensor(2.))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-0794e81913d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/jit/_trace.py\u001b[0m in \u001b[0;36mtrace\u001b[0;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m    783\u001b[0m         \u001b[0mstrict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[0m_force_outplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 785\u001b[0;31m         \u001b[0mget_callable_argument_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    786\u001b[0m     )\n\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-0794e81913d7>\u001b[0m in \u001b[0;36mfn\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused)\u001b[0m\n\u001b[1;32m    223\u001b[0m     return Variable._execution_engine.run_backward(\n\u001b[1;32m    224\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m         inputs, allow_unused, accumulate_grad=False)\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Cannot insert a Tensor that requires grad as a constant. Consider making it a parameter or input, or detaching the gradient\nTensor:\n2\n[ torch.FloatTensor{} ]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rztOk3U_YUF8"
      },
      "source": [
        "## JAX NUTS example: Code for leapfrog integrator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCAFawUDxlWJ",
        "outputId": "e0dff61b-3888-47aa-8228-b7128457fd9a"
      },
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "print('jax version: ', jax.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "jax version:  0.2.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p20OInvyhQQL"
      },
      "source": [
        "from collections import namedtuple\n",
        "import jax\n",
        "from jax import grad, jit, partial, random, value_and_grad, lax\n",
        "from jax.flatten_util import ravel_pytree\n",
        "import jax.numpy as np\n",
        "from jax import random\n",
        "from jax.tree_util import register_pytree_node, tree_multimap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZWlB6sHSEsa"
      },
      "source": [
        "# (q, p) -> (position (param value), momentum)\n",
        "\n",
        "IntegratorState = namedtuple(\"IntegratorState\", [\"q\", \"p\", \"potential_energy\", \"q_grad\"])\n",
        "\n",
        "# a tree-like JAX primitive that allows program transformations\n",
        "# to work on Python containers (https://jax.readthedocs.io/en/latest/pytrees.html)\n",
        "register_pytree_node(\n",
        "    IntegratorState,\n",
        "    lambda xs: (tuple(xs), None),\n",
        "    lambda _, xs: IntegratorState(*xs)\n",
        ")\n",
        "\n",
        "\n",
        "def leapfrog(potential_fn, kinetic_fn):\n",
        "    r\"\"\"\n",
        "    Second order symplectic integrator that uses the leapfrog algorithm\n",
        "    for position `q` and momentum `p`.\n",
        "\n",
        "    :param potential_fn: Python callable that computes the potential energy\n",
        "        given input parameters. The input parameters to `potential_fn` can be\n",
        "        any python collection type.\n",
        "    :param kinetic_fn: Python callable that returns the kinetic energy given\n",
        "        inverse mass matrix and momentum.\n",
        "    :return: a pair of (`init_fn`, `update_fn`).\n",
        "    \"\"\"\n",
        "    def init_fn(q, p):\n",
        "        \"\"\"\n",
        "        :param q: Position of the particle.\n",
        "        :param p: Momentum of the particle.\n",
        "        :return: initial state for the integrator.\n",
        "        \"\"\"\n",
        "        potential_energy, q_grad = value_and_grad(potential_fn)(q)\n",
        "        return IntegratorState(q, p, potential_energy, q_grad)\n",
        "\n",
        "    def update_fn(step_size, inverse_mass_matrix, state):\n",
        "        \"\"\"\n",
        "        :param float step_size: Size of a single step.\n",
        "        :param inverse_mass_matrix: Inverse of mass matrix, which is used to\n",
        "            calculate kinetic energy.\n",
        "        :param state: Current state of the integrator.\n",
        "        :return: new state for the integrator.\n",
        "        \"\"\"\n",
        "        q, p, _, q_grad = state\n",
        "        # maps a function over a pytree, returning a new pytree\n",
        "        p = tree_multimap(lambda p, q_grad: p - 0.5 * step_size * q_grad, p, q_grad)  # p(n+1/2)\n",
        "        p_grad = grad(kinetic_fn, argnums=1)(inverse_mass_matrix, p)\n",
        "        q = tree_multimap(lambda q, p_grad: q + step_size * p_grad, q, p_grad)  # q(n+1)\n",
        "        potential_energy, q_grad = value_and_grad(potential_fn)(q)\n",
        "        p = tree_multimap(lambda p, q_grad: p - 0.5 * step_size * q_grad, p, q_grad)  # p(n+1)\n",
        "        return IntegratorState(q, p, potential_energy, q_grad)\n",
        "\n",
        "    return init_fn, update_fn\n",
        "\n",
        "\n",
        "def kinetic_fn(inverse_mass_matrix, p):\n",
        "    # flattens the pytree\n",
        "    p, _ = ravel_pytree(p)\n",
        "\n",
        "    if inverse_mass_matrix.ndim == 2:\n",
        "        v = np.matmul(inverse_mass_matrix, p)\n",
        "    elif inverse_mass_matrix.ndim == 1:\n",
        "        v = np.multiply(inverse_mass_matrix, p)\n",
        "\n",
        "    return 0.5 * np.dot(v, p)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYsK_oXEjHdO"
      },
      "source": [
        "Note that jax provides some great utilities that let us operate on [pytrees](https://jax.readthedocs.io/en/latest/jax.tree_util.html?highlight=pytree#module-jax.tree_util) which can be any python container type that support packing/unpacking implementations. e.g. `tree_multimap` above. this lets us write generic code without imposing any assumptions on the client code. e.g. `potential_fn` could be a list or a simple array and the integrator code remains the same."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQrb7lQF9yfh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48c7319d-8fc3-4c07-8c76-5c40eab44147"
      },
      "source": [
        "D = 1000    \n",
        "\n",
        "true_mean, true_std = np.ones(D), np.ones(D) * 2.\n",
        "\n",
        "def potential_fn(q):\n",
        "    \"\"\"\n",
        "    - log density for the normal distribution\n",
        "    \"\"\"\n",
        "    return 0.5 * np.sum(((q['z'] - true_mean) / true_std) ** 2)    \n",
        "\n",
        "\n",
        "# U-turn termination condition\n",
        "# For demonstration purpose - this won't result in a correct MCMC proposal\n",
        "def is_u_turning(q_i, q_f, p_f):\n",
        "  return np.less(np.dot((q_f['z'] - q_i['z']), p_f['z']), 0)\n",
        "\n",
        "\n",
        "# Run leapfrog until termination condition is met\n",
        "def get_final_state(ke, pe, m_inv, step_size, q_i, p_i):\n",
        "    lf_init, lf_update = leapfrog(pe, ke)\n",
        "    lf_init_state = lf_init(q_i, p_i)\n",
        "    q_f, p_f, _, _ = lax.while_loop(lambda x: is_u_turning(q_i, x[0], x[1]), \n",
        "                                    lambda x: lf_update(step_size, m_inv, x),\n",
        "                                    lf_init_state)\n",
        "    return (q_f, p_f)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDaPP3sUnbFq"
      },
      "source": [
        "### jit and grad composition\n",
        "\n",
        "Note that we are jit compiling the integrator which includes grad computation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2r_TJUVdmN0G",
        "outputId": "743d9128-a013-4211-d0ae-04a1979ee2b8"
      },
      "source": [
        "q_i = {'z': np.zeros(D)}\n",
        "p_i = lambda i: {'z': random.normal(random.PRNGKey(i), (D,))}\n",
        "inv_mass_matrix = np.eye(D)\n",
        "step_size = 0.001\n",
        "  \n",
        "fn = jit(get_final_state, static_argnums=(0, 1))\n",
        "timefn = lambda i: fn(kinetic_fn, potential_fn, inv_mass_matrix, \n",
        "                      step_size, q_i, p_i(i))\n",
        "\n",
        "# Run only once in a loop; otherwise the best number reported \n",
        "# does not include compilation time.\n",
        "%timeit -n 1 -r 1 [timefn(0) for i in range(10)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 loop, best of 1: 20.4 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s899WWJynJu-"
      },
      "source": [
        "### Lets add vmap to do this in parallel\n",
        "\n",
        "Note that this requires:\n",
        " - composition of `vmap` with `jit` for `get_final_state`.\n",
        " - composition of `vmap` with control flow primitive `while` in `get_final_state`.\n",
        " - also composition of `vmap` and `jit` with `grad` in leapfrog."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JXfmzX3nIy6",
        "outputId": "ca9ec2b4-a46b-42b3-b9d3-86fcaff632c2"
      },
      "source": [
        "# Draw K in parallel\n",
        "\n",
        "K = 50\n",
        "q_i = {'z': random.normal(random.PRNGKey(1), (K, D))}\n",
        "p_i = {'z': random.normal(random.PRNGKey(2), (K, D))}\n",
        "jax.vmap(lambda z: fn(kinetic_fn, potential_fn, inv_mass_matrix, \n",
        "                      step_size, *z))((q_i, p_i))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'z': DeviceArray([[-0.6775011 ,  1.2218331 ,  0.34814987, ..., -0.1360297 ,\n",
              "                 0.09302761, -0.8675127 ],\n",
              "               [ 0.5821763 ,  0.11254374, -1.0764872 , ..., -0.10364341,\n",
              "                -0.84956676,  1.1980356 ],\n",
              "               [ 1.1932558 ,  0.69470936, -1.1416658 , ..., -1.3943284 ,\n",
              "                 0.06114601, -0.891614  ],\n",
              "               ...,\n",
              "               [ 1.4670084 , -0.27074087, -0.5646535 , ..., -0.85916924,\n",
              "                -0.7521342 , -1.5170535 ],\n",
              "               [-1.9934872 ,  0.6114559 ,  0.26292798, ..., -0.65967107,\n",
              "                -1.3601958 , -0.3978807 ],\n",
              "               [-0.65449744, -0.30205557,  0.6561341 , ..., -0.41573793,\n",
              "                 0.952913  ,  0.05202565]], dtype=float32)},\n",
              " {'z': DeviceArray([[-0.5898306 , -0.86168784, -0.6559259 , ..., -0.7063382 ,\n",
              "                 0.5879463 , -0.7263582 ],\n",
              "               [-0.8124092 ,  1.1634269 ,  0.67753744, ...,  0.0677776 ,\n",
              "                -0.38750023,  0.1552683 ],\n",
              "               [-0.5380241 ,  2.0605252 ,  1.073202  , ...,  1.7836542 ,\n",
              "                -0.62132597,  1.1611235 ],\n",
              "               ...,\n",
              "               [ 1.067331  , -0.43446946, -1.9700644 , ..., -1.861806  ,\n",
              "                -0.63302743, -1.4553517 ],\n",
              "               [-0.15199734,  0.8586823 ,  1.0224047 , ...,  1.0103161 ,\n",
              "                 0.6898258 , -0.09465612],\n",
              "               [-2.0981812 ,  0.0180762 , -1.1424608 , ..., -0.676896  ,\n",
              "                -0.8549366 ,  0.2972163 ]], dtype=float32)})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hV_wTvKG9Xli"
      },
      "source": [
        "## PyTorch NUTS example: LeapFrog Integrator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3RtbXOj9b31"
      },
      "source": [
        "def leapfrog(q, p, potential_fn, inverse_mass_matrix, step_size, num_steps=1, q_grads=None):\n",
        "    r\"\"\"\n",
        "    Second order symplectic integrator that uses the velocity leapfrog algorithm.\n",
        "\n",
        "    :param dict q: dictionary of sample site names and their current values\n",
        "        (type :class:`~torch.Tensor`).\n",
        "    :param dict p: dictionary of sample site names and corresponding momenta\n",
        "        (type :class:`~torch.Tensor`).\n",
        "    :param callable potential_fn: function that returns potential energy given q\n",
        "        for each sample site. The negative gradient of the function with respect\n",
        "        to ``q`` determines the rate of change of the corresponding sites'\n",
        "        momenta ``r``.\n",
        "    :param torch.Tensor inverse_mass_matrix: a tensor :math:`M^{-1}` which is used\n",
        "        to calculate kinetic energy: :math:`E_{kinetic} = \\frac{1}{2}z^T M^{-1} q`.\n",
        "        Here :math:`M` can be a 1D tensor (diagonal matrix) or a 2D tensor (dense matrix).\n",
        "    :param float step_size: step size for each time step iteration.\n",
        "    :param int num_steps: number of discrete time steps over which to integrate.\n",
        "    :param torch.Tensor q_grads: optional gradients of potential energy at current ``q``.\n",
        "    :return tuple (q_next, p_next, q_grads, potential_energy): next position and momenta,\n",
        "        together with the potential energy and its gradient w.r.t. ``q_next``.\n",
        "    \"\"\"\n",
        "    q_next = q.copy()\n",
        "    p_next = p.copy()\n",
        "    for _ in range(num_steps):\n",
        "        q_next, p_next, q_grads, potential_energy = _single_step(q_next,\n",
        "                                                                 p_next,\n",
        "                                                                 potential_fn,\n",
        "                                                                 inverse_mass_matrix,\n",
        "                                                                 step_size,\n",
        "                                                                 q_grads)\n",
        "    return q_next, p_next, q_grads, potential_energy\n",
        "\n",
        "\n",
        "def _single_step(q, p, potential_fn, inverse_mass_matrix, step_size, q_grads=None):\n",
        "    r\"\"\"\n",
        "    Single step leapfrog that modifies the `q`, `p` dicts in place.\n",
        "    \"\"\"\n",
        "\n",
        "    q_grads = _potential_grad(potential_fn, q)[0] if q_grads is None else q_grads\n",
        "\n",
        "    for site_name in p:\n",
        "        p[site_name] = p[site_name] + 0.5 * step_size * (-q_grads[site_name])  # p(n+1/2)\n",
        "\n",
        "    p_grads = _kinetic_grad(inverse_mass_matrix, p)\n",
        "    for site_name in q:\n",
        "        q[site_name] = q[site_name] + step_size * p_grads[site_name]  # q(n+1)\n",
        "\n",
        "    q_grads, potential_energy = _potential_grad(potential_fn, q)\n",
        "    for site_name in p:\n",
        "        p[site_name] = p[site_name] + 0.5 * step_size * (-q_grads[site_name])  # p(n+1)\n",
        "\n",
        "    return q, p, q_grads, potential_energy\n",
        "\n",
        "\n",
        "def _potential_grad(potential_fn, q):\n",
        "    q_keys, q_nodes = zip(*q.items())\n",
        "    for node in q_nodes:\n",
        "        node.requires_grad_(True)\n",
        "    potential_energy = potential_fn(q)\n",
        "    grads = torch.autograd.grad(potential_energy, q_nodes)\n",
        "    for node in q_nodes:\n",
        "        node.requires_grad_(False)\n",
        "    return dict(zip(q_keys, grads)), potential_energy.detach()\n",
        "\n",
        "\n",
        "def _kinetic_grad(inverse_mass_matrix, p):\n",
        "    p_flat = torch.cat([p[site_name].reshape(-1) for site_name in sorted(p)])\n",
        "    if inverse_mass_matrix.dim() == 1:\n",
        "        grads_flat = inverse_mass_matrix * p_flat\n",
        "    else:\n",
        "        grads_flat = inverse_mass_matrix.matmul(p_flat)\n",
        "\n",
        "    # unpacking\n",
        "    grads = {}\n",
        "    pos = 0\n",
        "    for site_name in sorted(p):\n",
        "        next_pos = pos + p[site_name].numel()\n",
        "        grads[site_name] = grads_flat[pos:next_pos].reshape(p[site_name].shape)\n",
        "        pos = next_pos\n",
        "    assert pos == grads_flat.size(0)\n",
        "    return grads"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkhUbaUu9wlL"
      },
      "source": [
        "D = 1000\n",
        "\n",
        "true_mean, true_std = 1, 2.\n",
        "\n",
        "def potential_fn(params):\n",
        "    return 0.5 * torch.sum(((params['z'] - true_mean) / true_std) ** 2)\n",
        "\n",
        "# U-turn termination condition\n",
        "# For demonstration purpose - this won't result in a correct MCMC proposal\n",
        "def is_u_turning(q_i, q_f, p_f):\n",
        "  return torch.dot((q_f['z'] - q_i['z']), p_f['z']) < 0.\n",
        "\n",
        "\n",
        "# Run leapfrog until termination condition is met\n",
        "def get_final_state(pe, m_inv, step_size, q_i, p_i):\n",
        "    q, p = q_i, p_i\n",
        "    q_grads = None\n",
        "    while not is_u_turning(q_i, q, p):\n",
        "      q, p, q_grads, _ = leapfrog(q, p, pe, m_inv, step_size, q_grads=q_grads)\n",
        "    return (q, p)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-pRvIEfGnW-"
      },
      "source": [
        "q_i = {'z': torch.zeros(D)}\n",
        "p_i = {'z': torch.randn(D)}\n",
        "inv_mass_matrix = torch.eye(D)\n",
        "step_size = 0.001\n",
        "num_steps = 10000 \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F04GgnBtifYM",
        "outputId": "e1799cb2-5e70-4f20-b011-4d83e3ad4e42"
      },
      "source": [
        "%timeit -n 1 -r 1 get_final_state(potential_fn, inv_mass_matrix, step_size, q_i, p_i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 loop, best of 1: 1.78 s per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-Cd0JfS3Xrk"
      },
      "source": [
        "### jit, grad, and vmap\n",
        "Unlike in JAX, the PyTorch JIT cannot yet inline and optimize grad calls. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsTpj5Ib3VOn"
      },
      "source": [
        "torch.jit.trace(lambda q, p: get_final_state(potential_fn, inv_mass_matrix, step_size, q, p), (q_i, p_i))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zmgrL6k3imM"
      },
      "source": [
        "And there remain unsupported ops for vmap batching."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "id": "b75fFNXn3ea_",
        "outputId": "bb73788c-7808-426e-b8e8-01f329c9cdbe"
      },
      "source": [
        "K = 50\n",
        "q_i = {'z': torch.randn(K, D)}\n",
        "p_i = {'z': torch.randn(K, D)}\n",
        "torch.vmap(lambda q, p: get_final_state(potential_fn, inv_mass_matrix, step_size, q, p))(q_i, p_i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: torch.vmap is an experimental prototype that is subject to change and/or deletion. Please use at your own risk. There may be unexpected performance cliffs due to certain operators not being implemented. To see detailed performance warnings please use `torch._C._debug_only_display_vmap_fallback_warnings(True) before the call to `vmap`.\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-59796a63ddb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mq_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'z'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mp_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'z'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mget_final_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpotential_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minv_mass_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/_vmap_internals.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0mbatched_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_batched_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmap_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m             \u001b[0mbatched_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatched_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m             \u001b[0m_validate_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatched_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_unwrap_batched\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatched_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmap_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-59796a63ddb5>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(q, p)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mq_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'z'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mp_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'z'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mget_final_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpotential_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minv_mass_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-18-c6f6b5a1e6e4>\u001b[0m in \u001b[0;36mget_final_state\u001b[0;34m(pe, m_inv, step_size, q_i, p_i)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_i\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mq_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_u_turning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m       \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_grads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleapfrog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_inv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_grads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mq_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Batching rule not implemented for aten::is_nonzero. We could not generate a fallback."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3URBZvuod6-3"
      },
      "source": [
        "## Helpful References\n",
        "1. [NUTS paper](https://arxiv.org/abs/1111.4246)\n",
        "2. [NUTS JAX implementation](https://github.com/pyro-ppl/numpyro/blob/master/numpyro/infer/hmc.py)\n",
        "\n",
        "  a. [Iterative NUTS numpyro (unrolling the recursive algorithm for JITting and vmap)](https://github.com/pyro-ppl/numpyro/wiki/Iterative-NUTS)\n",
        "\n",
        "  b. [Iterative NUTS tfp](https://github.com/tensorflow/probability/blob/master/discussion/technical_note_on_unrolled_nuts.md)\n",
        "\n",
        "3. [NUTS PyTorch implementation (fbinternal)](https://www.internalfb.com/intern/diffusion/FBS/browse/master/fbcode/beanmachine/beanmachine/ppl/inference/proposer/single_site_no_u_turn_sampler_proposer.py?commit=68b1672d648dba714d3f7c2ce13494b01925b103&lines=18)"
      ]
    }
  ]
}